{
 "metadata": {
  "name": "",
  "signature": "sha256:e2dcd560407fccd484e390bf329f8fa5b8310ec59b850ad7d0a2da1b2ec4e468"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Getting Started with Predictive Services"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this notebook we show how to set up a GraphLab Predictive Service deployment, to enable low-latency REST queries of trained machine learning models from a cluster of EC2 instances. For more information, see the [Predictive Services](http://graphlab.com/learn/userguide/index.html#Deployment_GraphLab_Predictive_Services) section of the User Guide.\n",
      "\n",
      "We show how easy it is to: \n",
      "\n",
      "1. Launch a Predictive Service deployment\n",
      "1. Add new Predictive Objects\n",
      "1. Update existing Predictive Objects\n",
      "1. Monitor deployment status\n",
      "1. Query deployed Predictive Objects\n",
      "1. Integrate deployment into an application\n",
      "1. Terminate the Predictive Service deployment\n",
      "\n",
      "**Note: This notebook uses GraphLab Create 1.1.**"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import graphlab"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Define EC2 Environment\n",
      "\n",
      "To launch a Predictive Service deployment we need to specify the EC2 metadata associated with this deployment. This metadata includes the region (defaults to us-west-2), instance type (defaults to m3.xlarge), and s3 bucket/path for logs. To easily set this metadata once and use it throughout GraphLab Predictive Services and GraphLab Data Pipelines, we create an [Environment](http://graphlab.com/products/create/docs/generated/graphlab.deploy.environment.EC2.html#graphlab.deploy.environment.EC2) object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "env = graphlab.deploy.environment.EC2('pred_intro',                      # name of environment\n",
      "                                      's3://gl-rajat-testing/logs',      # s3 log path for environment\n",
      "                                      region='us-west-2',\n",
      "                                      instance_type='m3.xlarge',\n",
      "                                      aws_access_key='YOUR_ACCESS_KEY', \n",
      "                                      aws_secret_key='YOUR_SECRET_KEY',\n",
      "                                      num_hosts=1)\n",
      "env.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After creating this object, we save it to the workbench, so we can easily retrieve it in subsequent GraphLab Create sessions. For more documentation about the workbench, see [here](http://graphlab.com/products/create/docs/graphlab.deploy.environments.html#graphlab.deploy.environments)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Launch the Predictive Service Deployment\n",
      "\n",
      "To launch a Predictive Service Deployment the API is [graphlab.deploy.predictive_service.create](http://graphlab.com/products/create/docs/generated/graphlab.deploy.predictive_service.create.html#graphlab.deploy.predictive_service.create). The required parameters are a name for the deployment, the environment metadata we defined in the previous step, and an S3 path for the root 'working directory' for this Predictive Service. This path is where the models and predictive objects will be uploaded, and where logs will be written for this Predictive Service.\n",
      "\n",
      "When this command is executed the EC2 instances will be launched immediately, then a load balancer will be launched, configured, and finally the load balancer will add the instances into the cluster as they pass health checks. The Predictive Service object will also be added to the workbench, so the deployment can be easily loaded in a later Python session."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment = graphlab.deploy.predictive_service.create('sample-service', env, 's3://gl-rajat-testing/pred-root/sample-service')\n",
      "deployment.save()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are other parameters which are optional, like specifying an SSL credential pair for HTTPS, specifying API keys and Admin keys (API keys enable REST queries, Admin keys enable adding/modifying the deployment), and the number of hosts in the cluster.\n",
      "\n",
      "Print the deployment to see the details about this deployment. This shows the information necessary to connect to the deployment from an application, which predictive objects (models) are deployed, and whether there are any pending changes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "Name: sample-service\n",
        "S3 Path: s3://gl-rajat-testing/pred-root/sample-service\n",
        "Description: None\n",
        "API Key: bb442acf-33af-4fb6-8af4-5fd92819dc59\n",
        "Load Balancer DNS Name: sample-service-1213776001.us-west-2.elb.amazonaws.com\n",
        "\n",
        "Deployed predictive objects:\n",
        "No Pending changes."
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Visualize Predictive Service\n",
      "\n",
      "GraphLab Canvas shows the details of this Predictive Service, and provides the introductory monitoring dashboard for the cluster. See the API documentation [here](http://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.show.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.show)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Prepare a Predictive Object (train a Model)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now that the cluster is ready, let's quickly train a Model to upload to this deployment. Each GraphLab Model is a Predictive Object. Custom Predictive Objects can also be specified by writing a function in Python, see the [User Guide](http://graphlab.com/learn/userguide/index.html#Deployment_GraphLab_Predictive_Services_Working_with_Predictive_Objects) for more information."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data_url = 'https://s3.amazonaws.com/GraphLab-Datasets/movie_ratings/sample.small'\n",
      "data = graphlab.SFrame.read_csv(data_url,delimiter='\\t',column_type_hints={'rating':int})\n",
      "(train_set, test_set) = data.random_split(0.8)\n",
      "model = graphlab.popularity_recommender.create(train_set, 'user', 'movie', 'rating')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>PROGRESS: Read 1549015 lines. Lines per second: 1.11495e+06</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Read 1549015 lines. Lines per second: 1.11495e+06"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Finished parsing file https://s3.amazonaws.com/GraphLab-Datasets/movie_ratings/sample.small</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Finished parsing file https://s3.amazonaws.com/GraphLab-Datasets/movie_ratings/sample.small"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Parsing completed. Parsed 4000000 lines in 2.0638 secs.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Parsing completed. Parsed 4000000 lines in 2.0638 secs."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Recsys training: model = popularity</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Recsys training: model = popularity"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Preparing data set.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Preparing data set."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS:     Data has 3200133 observations with 12020 users and 17184 items.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS:     Data has 3200133 observations with 12020 users and 17184 items."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS:     Data prepared in: 3.61976s</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS:     Data prepared in: 3.61976s"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: 3200133 observations to process; with 17184 unique items.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: 3200133 observations to process; with 17184 unique items."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: 3200133 observations processed.</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: 3200133 observations processed."
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: Number observations / second: 2.61575e+07</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: Number observations / second: 2.61575e+07"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: +------------+--------------+</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: +------------+--------------+"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | Tree level | Elapsed Time |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | Tree level | Elapsed Time |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: +------------+--------------+</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: +------------+--------------+"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | 0          | 2.085ms      |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | 0          | 2.085ms      |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | 1          | 4.463ms      |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | 1          | 4.463ms      |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | 2          | 6.35ms       |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | 2          | 6.35ms       |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | 3          | 8.246ms      |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | 3          | 8.246ms      |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | 4          | 10.299ms     |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | 4          | 10.299ms     |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: | 5          | 11.207ms     |</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: | 5          | 11.207ms     |"
       ]
      },
      {
       "html": [
        "<pre>PROGRESS: +------------+--------------+</pre>"
       ],
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "PROGRESS: +------------+--------------+"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Add the Predictive Object to the deployment, then apply changes\n",
      "\n",
      "Adding a Predictive Object stages this Predictive Object to be deployed to the cluster. To add a predictive object specify a name (which will be used in the URI to query the model in the REST API), and then specify the model object (or a path to the model). See the API documentation [here](http://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.add.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.add)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.add('recs', model, description='Sample Recommender')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now if you print the deployment there will be a pending predictive object that was just added."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "Name: sample-service\n",
        "S3 Path: s3://gl-rajat-testing/pred-root/sample-service\n",
        "Description: None\n",
        "API Key: bb442acf-33af-4fb6-8af4-5fd92819dc59\n",
        "Load Balancer DNS Name: sample-service-1213776001.us-west-2.elb.amazonaws.com\n",
        "\n",
        "Deployed predictive objects:\n",
        "Pending changes: \n",
        "\tAdding: recs"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Updating an existing model\n",
      " \n",
      "To update an existing model or predictive object, use the [update](http://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.update.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.update) method. Update will increment the version of an existing predictive object. When published, the updated model will be proactively warmed in the distributed cache, and existing cached entries for this model will be expired in 15 minutes."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To complete the publishing of this Predictive Object (model), call the [apply_changes](http://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.apply_changes.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.apply_changes) method. By calling this API the pending predictive objects will be uploaded to S3, and the cluster will be notified to download them from S3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.apply_changes()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To see the status of the deployment, call the get_status API."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.get_status()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "SERVICE\n",
        "Name: sample-service\n",
        "S3 Path: s3://gl-rajat-testing/pred-root/sample-service\n",
        "Description: None\n",
        "API Key: bb442acf-33af-4fb6-8af4-5fd92819dc59\n",
        "Load Balancer DNS Name: sample-service-1213776001.us-west-2.elb.amazonaws.com\n",
        "\n",
        "Deployed predictive objects:\n",
        "\tname: recs, version: 1\n",
        "No Pending changes.\n",
        "\n",
        "HOSTS\n",
        "ec2-54-149-53-237.us-west-2.compute.amazonaws.com (id: i-2803a724)\n",
        "State: InService\n",
        "Serving Models:\n",
        "[\n",
        "    {\n",
        "        \"description\":\"\",\n",
        "        \"name\":\"recs\",\n",
        "        \"status\":\"Loaded successfully\",\n",
        "        \"version\":1\n",
        "    }\n",
        "]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Query service (using a client library)\n",
      "\n",
      "Now to integrate this Predictive Service deployment into an application, next step is to query the REST API on the cluster. Below are two ways to query, one using curl which can be modified for any programming language needed, and the other is a convenience method provided by the Predictive Service object."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!curl -X POST -d '{\"api key\": \"API_KEY_VALUE\", \"data\":{\"method\":\"recommend\", \"data\":{\"users\":[\"Jacob Smith\"]}}}' http://DNS_NAME/data/recs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "recs = deployment.query('recs', {'method':'recommend', 'data':{'users':['Jacob Smith']}})\n",
      "recs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Terminate Predictive Services Deployment\n",
      "\n",
      "To terminate a Predictive Service, call the [terminate_service()](http://graphlab.com/products/create/docs/generated/graphlab.deploy._predictive_service._predictive_service.PredictiveService.terminate_service.html#graphlab.deploy._predictive_service._predictive_service.PredictiveService.terminate_service) API. There are options to delete the logs and predictive objects as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "deployment.terminate_service(remove_logs=True, remove_state=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is a lot more you can do with a Predictive Service. Spin one up for yourself and see how easy it is to consume a Model, or define your own Custom Predictive Object."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}